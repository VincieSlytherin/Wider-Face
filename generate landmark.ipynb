{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the landmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edify the load direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "landmark_imgs_save_dir='./train/anno_'\n",
    "save_file_name='image_list.txt'\n",
    "image_dir = './landmark_images/'\n",
    "\n",
    "with open('./trainImageList.txt') as f:\n",
    "    contents = f.readlines()\n",
    "    \n",
    "if not os.path.exists(landmark_imgs_save_dir):\n",
    "        os.makedirs(landmark_imgs_save_dir)\n",
    "        \n",
    "f2 = open(os.path.join(landmark_imgs_save_dir,save_file_name), 'w')\n",
    "\n",
    "for content in contents:\n",
    "    a=content.split('\\\\')\n",
    "    #print(a)\n",
    "    image_name = a[1].split(' ')\n",
    "    #print(image_name)\n",
    "    result = image_dir+a[0]+'/'+a[1]\n",
    "    f2.write(result)                  \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def IoU(box, boxes):\n",
    "    # box = (x1, y1, x2, y2)\n",
    "    box_area = (box[2] - box[0] + 1) * (box[3] - box[1] + 1)\n",
    "    area = (boxes[:, 2] - boxes[:, 0] + 1) * (boxes[:, 3] - boxes[:, 1] + 1)\n",
    "    \n",
    "    # abtain the offset of the interception \n",
    "    xx1 = np.maximum(box[0], boxes[:, 0])\n",
    "    yy1 = np.maximum(box[1], boxes[:, 1])\n",
    "    xx2 = np.minimum(box[2], boxes[:, 2])\n",
    "    yy2 = np.minimum(box[3], boxes[:, 3])\n",
    "\n",
    "    # compute the width and height of the bounding box\n",
    "    w = np.maximum(0, xx2 - xx1 + 1)\n",
    "    h = np.maximum(0, yy2 - yy1 + 1)\n",
    "\n",
    "    inter = w * h\n",
    "    ovr = inter / (box_area + area - inter)\n",
    "    return ovr\n",
    "\n",
    "\n",
    "def convert_to_square(bbox):\n",
    "    square_bbox = bbox.copy()\n",
    "    h = bbox[:, 3] - bbox[:, 1] + 1\n",
    "    w = bbox[:, 2] - bbox[:, 0] + 1\n",
    "    max_side = np.maximum(h,w)\n",
    "    square_bbox[:, 0] = bbox[:, 0] + w*0.5 - max_side*0.5\n",
    "    square_bbox[:, 1] = bbox[:, 1] + h*0.5 - max_side*0.5\n",
    "    square_bbox[:, 2] = square_bbox[:, 0] + max_side - 1\n",
    "    square_bbox[:, 3] = square_bbox[:, 1] + max_side - 1\n",
    "    return square_bbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the landmark file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import sys\n",
    "sys.path.append(os.getcwd())\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "prefix_path = ''\n",
    "traindata_store = './landmark_images/'\n",
    "annotation_file = \"./train/anno_/image_list.txt\"\n",
    "\n",
    "def gen_data(anno_file, data_dir, prefix):\n",
    "    size = 48\n",
    "    image_id = 0\n",
    "\n",
    "    landmark_imgs_save_dir = os.path.join(data_dir,\"48/landmark\")\n",
    "    if not os.path.exists(landmark_imgs_save_dir):\n",
    "        os.makedirs(landmark_imgs_save_dir)\n",
    "\n",
    "    anno_dir = './anno_store'\n",
    "    if not os.path.exists(anno_dir):\n",
    "        os.makedirs(anno_dir)\n",
    "\n",
    "    landmark_anno_filename = \"landmark_48.txt\"\n",
    "    save_landmark_anno = os.path.join(anno_dir,landmark_anno_filename)\n",
    "\n",
    "    # print(save_landmark_anno)\n",
    "    f = open(save_landmark_anno, 'w')\n",
    "\n",
    "    with open(anno_file, 'r') as f2:\n",
    "        annotations = f2.readlines()\n",
    "\n",
    "    num = len(annotations)\n",
    "    print(\"%d total images\" % num)\n",
    "\n",
    "    l_idx =0\n",
    "    idx = 0\n",
    "    for annotation in annotations:\n",
    "\n",
    "        annotation = annotation.strip().split(' ')\n",
    "        assert len(annotation)==15,\"each line should have 15 element\"\n",
    "        im_path = os.path.join(annotation[0].replace(\"\\\\\", \"/\"))\n",
    "        gt_box = list(map(float, annotation[1:5]))\n",
    "        gt_box = np.array(gt_box, dtype=np.int32)\n",
    "\n",
    "        landmark = list(map(float, annotation[5:]))\n",
    "        landmark = np.array(landmark, dtype=np.float)\n",
    "\n",
    "        img = cv2.imread(im_path)\n",
    "        print(im_path)\n",
    "        assert (img is not None)\n",
    "\n",
    "        height, width, channel = img.shape\n",
    "        idx = idx + 1\n",
    "        if idx % 100 == 0:\n",
    "            print(\"%d images done, landmark images: %d\"%(idx,l_idx))\n",
    "        # print(im_path)\n",
    "        # print(gt_box)\n",
    "        x1, x2, y1, y2 = gt_box\n",
    "        gt_box[1] = y1\n",
    "        gt_box[2] = x2\n",
    "\n",
    "        # gt's width\n",
    "        w = x2 - x1 \n",
    "        # gt's height\n",
    "        h = y2 - y1 \n",
    "        if min(w, h) < 5 or x1 < 0 or y1 < 0:\n",
    "            continue\n",
    "        # random shift\n",
    "        for i in range(10):\n",
    "            bbox_size = np.random.randint(int(min(w, h) * 0.8), np.ceil(1.25 * max(w, h)))\n",
    "            delta_x = np.random.randint(-w * 0.2, w * 0.2)\n",
    "            delta_y = np.random.randint(-h * 0.2, h * 0.2)\n",
    "            nx1 = max(x1 + w / 2 - bbox_size / 2 + delta_x, 0)\n",
    "            ny1 = max(y1 + h / 2 - bbox_size / 2 + delta_y, 0)\n",
    "\n",
    "            nx2 = nx1 + bbox_size\n",
    "            ny2 = ny1 + bbox_size\n",
    "            if nx2 > width or ny2 > height:\n",
    "                continue\n",
    "            crop_box = np.array([nx1, ny1, nx2, ny2])\n",
    "            cropped_im = img[int(ny1):int(ny2) + 1, int(nx1):int(nx2) + 1, :]\n",
    "            resized_im = cv2.resize(cropped_im, (size, size),interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "            offset_x1 = (x1 - nx1) / float(bbox_size)\n",
    "            offset_y1 = (y1 - ny1) / float(bbox_size)\n",
    "            offset_x2 = (x2 - nx2) / float(bbox_size)\n",
    "            offset_y2 = (y2 - ny2) / float(bbox_size)\n",
    "\n",
    "            offset_left_eye_x = (landmark[0] - nx1) / float(bbox_size)\n",
    "            offset_left_eye_y = (landmark[1] - ny1) / float(bbox_size)\n",
    "\n",
    "            offset_right_eye_x = (landmark[2] - nx1) / float(bbox_size)\n",
    "            offset_right_eye_y = (landmark[3] - ny1) / float(bbox_size)\n",
    "\n",
    "            offset_nose_x = (landmark[4] - nx1) / float(bbox_size)\n",
    "            offset_nose_y = (landmark[5] - ny1) / float(bbox_size)\n",
    "\n",
    "            offset_left_mouth_x = (landmark[6] - nx1) / float(bbox_size)\n",
    "            offset_left_mouth_y = (landmark[7] - ny1) / float(bbox_size)\n",
    "\n",
    "            offset_right_mouth_x = (landmark[8] - nx1) / float(bbox_size)\n",
    "            offset_right_mouth_y = (landmark[9] - ny1) / float(bbox_size)\n",
    "\n",
    "            # cal iou\n",
    "            iou =  IoU(crop_box.astype(np.float), np.expand_dims(gt_box.astype(np.float), 0))\n",
    "            print(iou)\n",
    "            # print(iou)\n",
    "            if iou > 0.65:\n",
    "                save_file = os.path.join(landmark_imgs_save_dir, \"%s.jpg\" % l_idx)\n",
    "                cv2.imwrite(save_file, resized_im)\n",
    "\n",
    "                f.write(save_file + ' -2 %.2f %.2f %.2f %.2f %.2f %.2f %.2f %.2f %.2f %.2f %.2f %.2f %.2f %.2f \\n' % \\\n",
    "                (offset_x1, offset_y1, offset_x2, offset_y2, \\\n",
    "                offset_left_eye_x,offset_left_eye_y,offset_right_eye_x,offset_right_eye_y,offset_nose_x,offset_nose_y,offset_left_mouth_x,offset_left_mouth_y,offset_right_mouth_x,offset_right_mouth_y))\n",
    "                # print(save_file)\n",
    "                # print(save_landmark_anno)\n",
    "                l_idx += 1\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    gen_data(annotation_file, traindata_store, prefix_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
